# product.py
# terminal command: streamlit run product.py
# OPENAI_API_KEY='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'
# 

import os
import streamlit as st
from langchain_community.chat_models import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage

# í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
openai_api_key = os.getenv("OPENAI_API_KEY")

# LangChain ChatOpenAI ì„¤ì •
chat_model = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7, openai_api_key=openai_api_key)

# Streamlit UI

st.title("ë”¥ëŸ¬ë‹ ê¸°ë°˜ ë‡Œì¢…ì–‘ ì§„ë‹¨ ë³´ê³ ì„œ")

# ì‚¬ìš©ì ì…ë ¥ê°’
st.header("MRI ë°ì´í„° ì…ë ¥")
distance = st.number_input("**ì¢…ì–‘ ì¤‘ì‹¬ê³¼ ë‡Œ ì¤‘ì‹¬ ê°„ ê±°ë¦¬ (í”½ì…€)**", min_value=0.0, format="%.2f")
size = st.number_input("**ì¢…ì–‘ í¬ê¸° (í”½ì…€ ìˆ˜)**", min_value=0, step=1)
irregularity = st.number_input("**ì¢…ì–‘ ë¶ˆê·œì¹™ì„± (ê¼­ì§“ì  ìˆ˜)**", min_value=0, step=1)
risk_score = st.number_input("**ìœ„í—˜ë„ ì ìˆ˜**", min_value=0.0, format="%.2f")

# ë²„íŠ¼ í´ë¦­ ì‹œ LLM í˜¸ì¶œ
if st.button("ê²°ê³¼ ë¶„ì„"):
    with st.spinner("LLM ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        # LangChain ë©”ì‹œì§€ êµ¬ì„±
        system_message = SystemMessage(
            content=(
                "ë‹¹ì‹ ì€ ë‡Œì¢…ì–‘ ë¶„ì„ì„ ì „ë¬¸ìœ¼ë¡œ í•˜ëŠ” ì˜ë£Œ ë³´ì¡°ì›ì…ë‹ˆë‹¤. "
                "MRI ë°ì´í„°ì—ì„œ ì¶”ì¶œí•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í™˜ìì—ê²Œ ì¢…ì–‘ì˜ ìœ„ì¹˜, í¬ê¸°, ë¶ˆê·œì¹™ì„±, "
                "ê·¸ë¦¬ê³  ê³„ì‚°ëœ ìœ„í—˜ë„ ì ìˆ˜ì— ëŒ€í•œ ìƒì„¸í•œ í•´ì„ì„ ì œê³µí•©ë‹ˆë‹¤. "
                "ë˜í•œ, í™˜ìì˜ ìƒí™©ì— ì í•©í•œ ë‹¤ìŒ ë‹¨ê³„ì˜ ê¶Œê³  ì‚¬í•­ì„ ì œì•ˆí•´ì•¼ í•©ë‹ˆë‹¤."
            )
        )

        user_message = HumanMessage(
            content=(
                f"ë‹¤ìŒ MRI ë°ì´í„°ì— ê¸°ë°˜í•˜ì—¬ ë‡Œì¢…ì–‘ì— ëŒ€í•œ ì˜í•™ì  í•´ì„ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:\n\n"
                f"- ì¢…ì–‘ ì¤‘ì‹¬ê³¼ ë‡Œ ì¤‘ì‹¬ ê°„ ê±°ë¦¬: {distance:.2f} í”½ì…€\n"
                f"- ì¢…ì–‘ í¬ê¸°: {size} í”½ì…€\n"
                f"- ì¢…ì–‘ ë¶ˆê·œì¹™ì„±(ê¼­ì§“ì  ê°œìˆ˜): {irregularity}\n"
                f"- ìœ„í—˜ë„ ì ìˆ˜: {risk_score:.2f}\n\n"
                "ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¢…ì–‘ì˜ ìœ„ì¹˜, í¬ê¸°, ëª¨ì–‘ì˜ ë¶ˆê·œì¹™ì„±ì´ í™˜ìì—ê²Œ ì–´ë–¤ ì˜ë¯¸ë¥¼ ê°€ì§€ëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”. "
                "ê³„ì‚°ëœ ìœ„í—˜ë„ ì ìˆ˜ë¥¼ í•´ì„í•˜ê³ , í™˜ìë¥¼ ìœ„í•œ ë‹¤ìŒ ë‹¨ê³„(ì¶”ê°€ ì§„ë‹¨ ë˜ëŠ” ì¹˜ë£Œ)ì— ëŒ€í•´ ê¶Œê³  ì‚¬í•­ì„ ì œì•ˆí•´ì£¼ì„¸ìš”. "
                "ìœ„í—˜ë„ ì ìˆ˜ì— ë”°ë¼ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¥¼ ì°¸ê³ í•˜ì„¸ìš”:\n"
                "- ìœ„í—˜ë„ ì ìˆ˜ <= 33: ë‚®ì€ ìœ„í—˜ë„\n"
                "- 34 <= ìœ„í—˜ë„ ì ìˆ˜ <= 66: ì¤‘ê°„ ìœ„í—˜ë„\n"
                "- ìœ„í—˜ë„ ì ìˆ˜ > 66: ë†’ì€ ìœ„í—˜ë„"
            )
        )

        # LLM í˜¸ì¶œ
        response = chat_model([system_message, user_message])
        
        # ê²°ê³¼ ì¶œë ¥
        st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

        # OpenAI GPT ê²°ê³¼ë¥¼ 3ê°œ íŒŒíŠ¸ë¡œ ë‚˜ëˆ„ê¸°
        response_content = response.content

        # êµ¬ë¶„ì "###"ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŒŒíŠ¸ ë‚˜ëˆ„ê¸°
        parts = response_content.split("###")

        # íŒŒíŠ¸ë³„ ì¶œë ¥
        # 1. ë¶„ì„ ê²°ê³¼
        st.subheader("ğŸ” ë¶„ì„ ê²°ê³¼")
        st.write("ì¢…ì–‘ì˜ íŠ¹ì„±ê³¼ ìœ„ì¹˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„ëœ ê²°ê³¼ì…ë‹ˆë‹¤.")
        st.write(parts[0])
        st.divider()  # êµ¬ë¶„ì„  ì¶”ê°€

        # 2. ì˜í•™ì  ê¶Œê³  ì‚¬í•­
        st.subheader("ğŸ©º ì˜í•™ì  ê¶Œê³  ì‚¬í•­")
        st.write("ì¢…ì–‘ì˜ ìœ„í—˜ë„ì™€ í˜„ì¬ ìƒíƒœë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ì¡°ì¹˜ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤:")
        st.write(parts[1])
        st.divider()

        # 3. ìµœì¢… ìš”ì•½
        st.subheader("ğŸ‘©â€âš•ï¸ ìµœì¢… ìš”ì•½")
        st.write("í˜„ì¬ ê´€ì°°ëœ ì¢…ì–‘ì˜ íŠ¹ì„±ê³¼ ìœ„í—˜ë„ì— ëŒ€í•œ ì¢…í•©ì ì¸ ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤.")
        st.write(parts[2])
