# product.py
# terminal command: streamlit run product.py 

import os
import streamlit as st
from langchain_community.chat_models import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage

# í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
openai_api_key = os.getenv("OPENAI_API_KEY")

# LangChain ChatOpenAI ì„¤ì •
chat_model = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7, openai_api_key=openai_api_key)

# Streamlit UI

st.title("ë”¥ëŸ¬ë‹ ê¸°ë°˜ ë‡Œì¢…ì–‘ ì§„ë‹¨ ë³´ê³ ì„œ")

# ì‚¬ìš©ì ì…ë ¥ê°’
st.header("MRI ë°ì´í„° ì…ë ¥")
distance = st.number_input("**ì¢…ì–‘ ì¤‘ì‹¬ê³¼ ë‡Œ ì¤‘ì‹¬ ê°„ ê±°ë¦¬ (í”½ì…€)**", min_value=0.0, format="%.2f")
size = st.number_input("**ì¢…ì–‘ í¬ê¸° (í”½ì…€ ìˆ˜)**", min_value=0, step=1)
irregularity = st.number_input("**ì¢…ì–‘ ë¶ˆê·œì¹™ì„± (ê¼­ì§“ì  ìˆ˜)**", min_value=0, step=1)
risk_score = st.number_input("**ìœ„í—˜ë„ ì ìˆ˜**", min_value=0.0, format="%.2f")

# ë²„íŠ¼ í´ë¦­ ì‹œ LLM í˜¸ì¶œ
if st.button("ê²°ê³¼ ë¶„ì„"):
    with st.spinner("LLM ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        # LangChain ë©”ì‹œì§€ êµ¬ì„±
        system_message = SystemMessage(
            content=(
                "ë‹¹ì‹ ì€ ë‡Œì¢…ì–‘ ë¶„ì„ì„ ì „ë¬¸ìœ¼ë¡œ í•˜ëŠ” ì˜ë£Œ ë³´ì¡°ì›ì…ë‹ˆë‹¤. "
                "MRI ë°ì´í„°ì—ì„œ ì¶”ì¶œí•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í™˜ìì—ê²Œ ì¢…ì–‘ì˜ ìœ„ì¹˜, í¬ê¸°, ë¶ˆê·œì¹™ì„±, "
                "ê·¸ë¦¬ê³  ê³„ì‚°ëœ ìœ„í—˜ë„ ì ìˆ˜ì— ëŒ€í•œ ìƒì„¸í•œ í•´ì„ì„ ì œê³µí•©ë‹ˆë‹¤. "
                "ë˜í•œ, í™˜ìì˜ ìƒí™©ì— ì í•©í•œ ë‹¤ìŒ ë‹¨ê³„ì˜ ê¶Œê³  ì‚¬í•­ì„ ì œì•ˆí•´ì•¼ í•©ë‹ˆë‹¤."
            )
        )

        user_message = HumanMessage(
            content=(
                f"ë‹¤ìŒ MRI ë°ì´í„°ì— ê¸°ë°˜í•˜ì—¬ ë‡Œì¢…ì–‘ì— ëŒ€í•œ ì˜í•™ì  í•´ì„ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:\n\n"
                f"- ì¢…ì–‘ ì¤‘ì‹¬ê³¼ ë‡Œ ì¤‘ì‹¬ ê°„ ê±°ë¦¬: {distance:.2f} í”½ì…€\n"
                f"- ì¢…ì–‘ í¬ê¸°: {size} í”½ì…€\n"
                f"- ì¢…ì–‘ ë¶ˆê·œì¹™ì„±(ê¼­ì§“ì  ê°œìˆ˜): {irregularity}\n"
                f"- ìœ„í—˜ë„ ì ìˆ˜: {risk_score:.2f}\n\n"
                "ì•„ë˜ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”. ê° ì„¹ì…˜ì€ ë°˜ë“œì‹œ '###'ë¡œ êµ¬ë¶„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤:\n"
                "### ë¶„ì„ ê²°ê³¼\n"
                "ì¢…ì–‘ì˜ ìœ„ì¹˜, í¬ê¸°, ë¶ˆê·œì¹™ì„± ë° ìœ„í—˜ë„ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\n"
                "### ì˜í•™ì  ê¶Œê³  ì‚¬í•­\n"
                "ì¢…ì–‘ì˜ ìƒíƒœë¥¼ ê³ ë ¤í•˜ì—¬ í•„ìš”í•œ ì˜í•™ì  ê¶Œê³  ì‚¬í•­ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n"
                "### ìµœì¢… ìš”ì•½\n"
                "í™˜ìì—ê²Œ ì „ë‹¬í•  ì¢…í•©ì ì¸ ìš”ì•½ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n\n"
                "ìœ„í—˜ë„ ì ìˆ˜ì— ë”°ë¼ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¥¼ ì°¸ê³ í•˜ì„¸ìš”:\n"
                "- ìœ„í—˜ë„ ì ìˆ˜ <= 33: ë‚®ì€ ìœ„í—˜ë„\n"
                "- 34 <= ìœ„í—˜ë„ ì ìˆ˜ <= 66: ì¤‘ê°„ ìœ„í—˜ë„\n"
                "- ìœ„í—˜ë„ ì ìˆ˜ > 66: ë†’ì€ ìœ„í—˜ë„"
            )
        )

        # LLM í˜¸ì¶œ ë° ì‘ë‹µ ì²˜ë¦¬
        response = chat_model([system_message, user_message])
        response_content = response.content

        # LLM ì‘ë‹µ í™•ì¸
        st.write("**LLM ì‘ë‹µ í™•ì¸:**", response_content)

        # êµ¬ë¶„ì "###"ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŒŒíŠ¸ ë‚˜ëˆ„ê¸°
        parts = response_content.split("###")

        # ë¶„ì„ ê²°ê³¼ ì¶œë ¥
        st.subheader("ğŸ” ë¶„ì„ ê²°ê³¼")
        if len(parts) > 1:
            st.write(parts[1].strip())
        else:
            st.warning("ë¶„ì„ ê²°ê³¼ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        st.divider()

        # ì˜í•™ì  ê¶Œê³  ì‚¬í•­ ì¶œë ¥
        st.subheader("ğŸ©º ì˜í•™ì  ê¶Œê³  ì‚¬í•­")
        if len(parts) > 2:
            st.write(parts[2].strip())
        else:
            st.warning("ì˜í•™ì  ê¶Œê³  ì‚¬í•­ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        st.divider()

        # ìµœì¢… ìš”ì•½ ì¶œë ¥
        st.subheader("ğŸ‘©â€âš•ï¸ ìµœì¢… ìš”ì•½")
        if len(parts) > 3:
            st.write(parts[3].strip())
        else:
            st.warning("ìµœì¢… ìš”ì•½ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
